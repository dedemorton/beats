[id="{beatname_lc}-getting-started"]
== Getting Started With {beatname_uc}

include::{libbeat-dir}/docs/shared-getting-started-intro.asciidoc[]

* <<{beatname_lc}-installation>>
* <<{beatname_lc}-configuration>>
* <<{beatname_lc}-template>>
* <<load-kibana-dashboards>>
* <<{beatname_lc}-starting>>
* <<view-kibana-dashboards>>
* <<setup-repositories>>

[id="{beatname_lc}-installation"]
=== Step 1: Download the {beatname_uc} package

The {beatname_uc} package contains the command line tools, configuration file,
and binary code required to run Beatless in your serverless environment. 

To download and extract the package, use the commands that work with your system
(<<deb, deb>> for Debian/Ubuntu, <<rpm, rpm>> for Redhat/Centos/Fedora, <<mac,
mac>> for OS X, and <<win, win>> for Windows).

TODO: Remove sections that aren't relevant here and fix the paths to reflect the
actual package names and download URLs.

[[deb]]
*deb:*

ifeval::["{release-state}"=="unreleased"]

Version {version} of {beatname_uc} has not yet been released.

endif::[]

ifeval::["{release-state}"!="unreleased"]

["source","sh",subs="attributes"]
------------------------------------------------
curl -L -O https://artifacts.elastic.co/downloads/beats/{beatname_lc}/{beatname_lc}-{version}-amd64.deb
sudo dpkg -i {beatname_lc}-{version}-amd64.deb
------------------------------------------------

endif::[]

[[rpm]]
*rpm:*

ifeval::["{release-state}"=="unreleased"]

Version {version} of {beatname_uc} has not yet been released.

endif::[]

ifeval::["{release-state}"!="unreleased"]

["source","sh",subs="attributes"]
------------------------------------------------
curl -L -O https://artifacts.elastic.co/downloads/beats/{beatname_lc}/{beatname_lc}-{version}-x86_64.rpm
sudo rpm -vi {beatname_lc}-{version}-x86_64.rpm
------------------------------------------------

endif::[]

[[mac]]
*mac:*

ifeval::["{release-state}"=="unreleased"]

Version {version} of {beatname_uc} has not yet been released.

endif::[]

ifeval::["{release-state}"!="unreleased"]

["source","sh",subs="attributes"]
------------------------------------------------
curl -L -O https://artifacts.elastic.co/downloads/beats/{beatname_lc}/{beatname_lc}-{version}-darwin-x86_64.tar.gz
tar xzvf {beatname_lc}-{version}-darwin-x86_64.tar.gz
------------------------------------------------

endif::[]

[[win]]
*win:*

ifeval::["{release-state}"=="unreleased"]

Version {version} of {beatname_uc} has not yet been released.

endif::[]

ifeval::["{release-state}"!="unreleased"]

. Download the {beatname_uc} Windows zip file from the
https://www.elastic.co/downloads/beats/{beatname_lc}[downloads page].

. Extract the contents of the zip file. 

endif::[]

[id="{beatname_lc}-configuration"]
=== Step 2: Configure {beatname_uc}

To run {beatname_uc} in your serverless environment, you need to define the
functions that will execute when specific triggers are invoked.

Before pushing {beatname_uc} code to your serverless environment, you need to
define details the functions that you want to deploy, including the
function name, type and triggers that will invoke the function. To do this, you
specify settings in the +{beatname_lc}.yml+ configuration file. You 
You also configure additional settings, such as processors to filter the data,
and you specify connection details for your {es} cluster.

The configuration file, +{beatname_lc}.yml+, is in the archive that you
extracted earlier.

TIP: See the
{libbeat}/config-file-format.html[Config File Format] section of the
_Beats Platform Reference_ for more about the structure of the config file.

The following example configures a function called `myfunction` that collects
events from Cloudwatch Logs and forwards the events to {es}.

QUESTION: For the initial release, will users need to explicitly disable any
options that write to disk (example below was taken from a demo, so not sure)?

TODO: Pare down this example.

["source","sh",subs="attributes"]
-------------------------------------------------------------------------------------
{beatname_lc}.provider.aws:
  functions:
    - name: ph
      type: cloudwatch_logs
      triggers:
        - log_group_name: /aws/lambda/TestingCloudwatchlogs
          filter_name: myfilter
cloud.id: ${cloud_id}
cloud.auth: ${cloud_auth}

output.elasticsearch:
  enabled: true
  hosts:

# Disable anything that could be send to disk
path.data: /tmp
path.logs: /tmp/logs
logging.to_stderr: true
logging.to_files: false
logging.level: debug
setup.template.enabled: true
queue.mem:
  events: 50
  flush.min_events: 1
  flush.timeout: 0.5s
-------------------------------------------------------------------------------------

To configure {beatname_uc}:

. Define the functions that will execute in your serverless environment.
+
TODO: Explain what is required (name, type?, one or more triggers, etc. Will
need to desribe triggers somewhere else maybe and refer to those?
+
["source","sh",subs="attributes"]
-------------------------------------------------------------------------------------
ADD AN EXAMPLE IF NEEDED
-------------------------------------------------------------------------------------

include::{libbeat-dir}/docs/step-configure-output.asciidoc[]

include::{libbeat-dir}/docs/step-configure-kibana-endpoint.asciidoc[]

include::{libbeat-dir}/docs/step-configure-credentials.asciidoc[]

include::{libbeat-dir}/docs/step-test-config.asciidoc[]

include::{libbeat-dir}/docs/step-look-at-config.asciidoc[]

[id="{beatname_lc}-template"]
=== Step 3: Load the index template in Elasticsearch

:allplatforms:
include::{libbeat-dir}/docs/shared-template-load.asciidoc[]

[[load-kibana-dashboards]]
=== Step 4: Set up the Kibana dashboards

:allplatforms:
include::{libbeat-dir}/docs/dashboards.asciidoc[]

[id="{beatname_lc}-starting"]
=== Step 5: Deploy {beatname_uc} code to your serverless environment

Before deploying functions to your serverless environment, make sure you're
logged in with the credentials required by your cloud service provider and that
the logged in user has the privileges (?) required to ???? (deploy and run
functions?)

The following command deploys the function named `myfunction`. See xxx for more
information about the `deploy` command.

//QUESTION: Which flags do we want to show in the example here? debug selectors?

*deb:*

["source","sh",subs="attributes"]
----------------------------------------------------------------------
{beatname_lc} function deploy myfunction
----------------------------------------------------------------------

*rpm:*

["source","sh",subs="attributes"]
----------------------------------------------------------------------
{beatname_lc} function deploy myfunction
----------------------------------------------------------------------

*mac:*

["source","sh",subs="attributes"]
----------------------------------------------------------------------
./{beatname_lc} function deploy myfunction
----------------------------------------------------------------------

*win:*

["source","sh",subs="attributes"]
----------------------------------------------------------------------
PS C:{backslash}Program Files{backslash}{beatname_uc}> Start-Service {beatname_lc}
----------------------------------------------------------------------


By default, Windows log files are stored in +C:\ProgramData\{beatname_lc}\Logs+.

{beatname_uc} is now ready to send log files to your defined output.

[[view-kibana-dashboards]]
=== Step 6: View the sample Kibana dashboards

To make it easier for you to explore {beatname_uc} data in Kibana, we've created
example {beatname_uc} dashboards. You loaded the dashboards earlier when you
ran the `setup` command.

include::{libbeat-dir}/docs/opendashboards.asciidoc[]

You can use these dashboards as examples and
{kibana-ref}/dashboard.html[customize] them to meet your needs.

To populate the example dashboards with data, you need to either
<<configuring-ingest-node,define ingest node pipelines>> or use Logstash to
parse the data into the fields expected by the dashboards. 

Here is an example of the {beatname_uc} ADD DASHBOARD NAME dashboard:

// Add an example of the dashboard
//[role="screenshot"]
//image:./images/add-image-name.png[]
